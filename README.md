
# AI Snake Game with SAC Algorithm

![Snake Game Screenshot](screenshot.png)

An AI-powered Snake game implementation using the Soft Actor-Critic (SAC) reinforcement learning algorithm with GPU acceleration.

## Table of Contents
- [Features](#features)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Training](#training)
- [Results](#results)
- [Technical Details](#technical-details)
- [License](#license)
- [ä¸­æ–‡è¯´æ˜](#ä¸­æ–‡è¯´æ˜)

## Features

- ğŸš€ **SAC Algorithm**: State-of-the-art reinforcement learning algorithm with maximum entropy objective
- âš¡ **GPU Acceleration**: Leverages PyTorch CUDA support for faster training
- ğŸ® **Interactive UI**: Real-time visualization of training process
- ğŸ“Š **Training Statistics**: Tracks scores, averages, and performance metrics
- âš™ï¸ **Customizable Parameters**: Adjustable hyperparameters for experimentation
- ğŸ–¥ï¸ **Visualization**: Colorful game interface with snake and food rendering

## Requirements

- Python 3.10+
- PyTorch (with CUDA if available)
- Pygame
- NumPy

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/XK-Byte/Snake-AI.git
   cd Snake-AI
   ```


## Usage

Run the game with default settings:
```bash
python snake_sac.py
```

Controls:
- **Start/Stop Training**: Click the "Start Training" button
- **Reset Game**: Click the "Reset Game" button
- **Speed Mode**: Toggle between fast training and normal speed

## Training

The SAC agent will automatically:
1. Collect experiences through gameplay
2. Update its neural networks periodically
3. Save model checkpoints every 100 episodes

Key hyperparameters (can be adjusted in code):
- Learning rate: 3e-4
- Batch size: 2048
- Replay buffer size: 4,000,000
- Gamma (discount factor): 0.99
- Tau (soft update coefficient): 0.005

## Results

Expected performance:
- Starts learning basic behaviors within 50 episodes
- Achieves consistent scores >20 after 200 episodes
- Can reach scores >50 with sufficient training

## Technical Details

### State Representation
The agent observes:
- Snake head position
- Food position (relative)
- Danger directions (wall/body collisions)
- Current movement direction

### Reward Structure
- +10 for eating food
- -10 for collisions
- Small penalties for inefficient movement
- Time penalty for not eating

### Network Architecture
- Policy Network: 2 hidden layers (512 units each)
- Q Networks: 2 hidden layers (512 units each)
- Activation: ReLU
- Optimization: Adam

## License

MIT License

## ä¸­æ–‡è¯´æ˜

# åŸºäºSACç®—æ³•çš„AIè´ªåƒè›‡æ¸¸æˆ

![æ¸¸æˆæˆªå›¾](screenshot.png)

ä½¿ç”¨Soft Actor-Critic (SAC)å¼ºåŒ–å­¦ä¹ ç®—æ³•å®ç°çš„AIè´ªåƒè›‡æ¸¸æˆï¼Œæ”¯æŒGPUåŠ é€Ÿã€‚

## ç›®å½•
- [åŠŸèƒ½ç‰¹ç‚¹](#åŠŸèƒ½ç‰¹ç‚¹)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
- [ä½¿ç”¨è¯´æ˜](#ä½¿ç”¨è¯´æ˜)
- [è®­ç»ƒè¿‡ç¨‹](#è®­ç»ƒè¿‡ç¨‹)
- [é¢„æœŸæ•ˆæœ](#é¢„æœŸæ•ˆæœ)
- [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
- [è®¸å¯è¯](#è®¸å¯è¯)

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸš€ **SACç®—æ³•**: é‡‡ç”¨æœ€å¤§ç†µç›®æ ‡çš„å…ˆè¿›å¼ºåŒ–å­¦ä¹ ç®—æ³•
- âš¡ **GPUåŠ é€Ÿ**: åˆ©ç”¨PyTorch CUDAæ”¯æŒåŠ é€Ÿè®­ç»ƒ
- ğŸ® **äº¤äº’å¼ç•Œé¢**: å®æ—¶å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
- ğŸ“Š **è®­ç»ƒç»Ÿè®¡**: è®°å½•åˆ†æ•°ã€å¹³å‡åˆ†å’Œæ€§èƒ½æŒ‡æ ‡
- âš™ï¸ **å¯è°ƒå‚æ•°**: å¯è°ƒæ•´è¶…å‚æ•°è¿›è¡Œå®éªŒ
- ğŸ–¥ï¸ **å¯è§†åŒ–ç•Œé¢**: å½©è‰²æ¸¸æˆç•Œé¢ï¼Œæ¸²æŸ“è›‡å’Œé£Ÿç‰©

## ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- PyTorch (æ¨èæ”¯æŒCUDAç‰ˆæœ¬)
- Pygame
- NumPy

## å®‰è£…æŒ‡å—

1. å…‹éš†ä»“åº“:
   ```bash
   git clone https://github.com/XK-Byte/Snake-AI.git
   cd Snake-AI
   ```



## ä½¿ç”¨è¯´æ˜

ä½¿ç”¨é»˜è®¤è®¾ç½®è¿è¡Œæ¸¸æˆ:
```bash
python snake_sac.py
```

æ“ä½œæ§åˆ¶:
- **å¼€å§‹/åœæ­¢è®­ç»ƒ**: ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®
- **é‡ç½®æ¸¸æˆ**: ç‚¹å‡»"é‡ç½®æ¸¸æˆ"æŒ‰é’®
- **é€Ÿåº¦æ¨¡å¼**: åˆ‡æ¢å¿«é€Ÿè®­ç»ƒå’Œæ­£å¸¸é€Ÿåº¦

## è®­ç»ƒè¿‡ç¨‹

SACæ™ºèƒ½ä½“ä¼šè‡ªåŠ¨:
1. é€šè¿‡æ¸¸æˆæ”¶é›†ç»éªŒ
2. å®šæœŸæ›´æ–°ç¥ç»ç½‘ç»œ
3. æ¯100è½®ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹

å…³é”®è¶…å‚æ•°(å¯åœ¨ä»£ç ä¸­è°ƒæ•´):
- å­¦ä¹ ç‡: 3e-4
- æ‰¹å¤§å°: 2048
- ç»éªŒå›æ”¾ç¼“å†²åŒº: 4,000,000
- Gamma(æŠ˜æ‰£å› å­): 0.99
- Tau(è½¯æ›´æ–°ç³»æ•°): 0.005

## é¢„æœŸæ•ˆæœ

é¢„æœŸè¡¨ç°:
- 50è½®å†…å­¦ä¹ åŸºæœ¬è¡Œä¸º
- 200è½®ååˆ†æ•°ç¨³å®š>20
- å……åˆ†è®­ç»ƒåå¯è¾¾åˆ°>50åˆ†

## æŠ€æœ¯ç»†èŠ‚

### çŠ¶æ€è¡¨ç¤º
æ™ºèƒ½ä½“è§‚å¯Ÿ:
- è›‡å¤´ä½ç½®
- é£Ÿç‰©ä½ç½®(ç›¸å¯¹åæ ‡)
- å±é™©æ–¹å‘(å¢™å£/èº«ä½“ç¢°æ’)
- å½“å‰ç§»åŠ¨æ–¹å‘

### å¥–åŠ±ç»“æ„
- åƒåˆ°é£Ÿç‰©: +10
- ç¢°æ’: -10
- ä½æ•ˆç§»åŠ¨: å°æƒ©ç½š
- é•¿æ—¶é—´ä¸åƒé£Ÿç‰©: æ—¶é—´æƒ©ç½š

### ç½‘ç»œæ¶æ„
- ç­–ç•¥ç½‘ç»œ: 2ä¸ªéšè—å±‚(å„512å•å…ƒ)
- Qç½‘ç»œ: 2ä¸ªéšè—å±‚(å„512å•å…ƒ)
- æ¿€æ´»å‡½æ•°: ReLU
- ä¼˜åŒ–å™¨: Adam

## è®¸å¯è¯

MITè®¸å¯è¯
```

This README includes:
1. Project title and screenshot placeholder
2. Bilingual sections (English/Chinese)
3. Clear installation and usage instructions
4. Technical specifications
5. Expected performance metrics
6. License information
7. Visual emoji markers for better readability

You should replace `yourusername` with your actual GitHub username and add a real screenshot.png file to the project directory.
